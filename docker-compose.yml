# Nubicustos Docker Compose Configuration
# All images pinned to specific versions for reproducibility

services:
  # ============================================================================
  # AWS Security Tools
  # ============================================================================

  prowler:
    image: toniblyx/prowler:4.2.4
    container_name: prowler
    profiles: ["tools", "aws"]
    volumes:
      - ./reports/prowler:/reports
      - ./credentials/aws:/home/prowler/.aws:ro
      - ./logs:/logs
    environment:
      - AWS_SHARED_CREDENTIALS_FILE=/home/prowler/.aws/credentials
      - AWS_CONFIG_FILE=/home/prowler/.aws/config
      - HOME=/home/prowler
    command: aws --output-formats json-ocsf html csv --output-directory /reports
    networks:
      - security-net
    restart: unless-stopped

  scoutsuite-aws:
    image: rossja/ncc-scoutsuite:latest
    container_name: scoutsuite-aws
    profiles: ["tools", "aws"]
    volumes:
      - ./reports/scoutsuite:/reports
      - ./credentials/aws:/root/.aws:ro
    command: --provider aws --report-dir /reports/aws --no-browser
    networks:
      - security-net
    restart: unless-stopped

  pacu:
    image: rhinosecuritylabs/pacu:latest
    container_name: pacu
    profiles: ["tools", "aws"]
    volumes:
      - ./reports/pacu:/reports
      - ./credentials/aws:/root/.aws:ro
      - pacu-data:/root/.local/share/pacu
    environment:
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
    networks:
      - security-net
    stdin_open: true
    tty: true
    restart: unless-stopped

  cloudfox:
    build:
      context: ./docker/cloudfox
      dockerfile: Dockerfile
    image: cloudfox:local
    container_name: cloudfox
    profiles: ["tools", "aws"]
    volumes:
      - ./reports/cloudfox:/reports
      - ./credentials/aws:/root/.aws:ro
      - ./credentials/gcp:/root/.config/gcloud:ro
      - ./credentials/azure:/root/.azure:ro
      - cloudfox-data:/root/.cloudfox
    environment:
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
      - AWS_CONFIG_FILE=/root/.aws/config
    command: cloudfox aws all-checks --output /reports
    networks:
      - security-net
    restart: unless-stopped

  enumerate-iam:
    build:
      context: ./tools/enumerate-iam
      dockerfile: Dockerfile
    container_name: enumerate-iam
    profiles: ["tools", "aws"]
    volumes:
      - ./reports/enumerate-iam:/reports
      - ./credentials/aws:/root/.aws:ro
    environment:
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
    networks:
      - security-net
    restart: unless-stopped

  # ============================================================================
  # Multi-Cloud Security Tools
  # ============================================================================

  cloudsploit:
    image: cloudsploit:local
    container_name: cloudsploit
    profiles: ["tools", "aws"]
    user: root
    volumes:
      - ./reports/cloudsploit:/reports
      - ./credentials/aws:/root/.aws:ro
    environment:
      - HOME=/root
      - AWS_DEFAULT_REGION=us-east-1
    entrypoint: ["node", "/var/scan/cloudsploit/index.js"]
    command: ["--cloud", "aws", "--compliance", "pci", "--console", "table", "--json", "/reports/output.json"]
    networks:
      - security-net
    restart: unless-stopped

  cloud-custodian:
    image: cloudcustodian/c7n:latest
    container_name: cloud-custodian
    profiles: ["tools", "aws"]
    volumes:
      - ./policies:/policies:ro
      - ./reports/custodian:/output
      - ./credentials/aws:/root/.aws:ro
      - ./logs:/logs
    environment:
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
    command: run -s /output --log-group=/logs/custodian.log /policies/*.yml
    networks:
      - security-net
    restart: unless-stopped

  cloudmapper:
    build: ./cloudmapper
    container_name: cloudmapper
    profiles: ["tools", "aws"]
    volumes:
      - ./reports/cloudmapper:/reports
      - ./credentials/aws:/root/.aws:ro
      - ./config/cloudmapper:/config:ro
    environment:
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
    networks:
      - security-net
    restart: unless-stopped

  # ============================================================================
  # Kubernetes Security Tools
  # ============================================================================

  kube-bench:
    image: aquasec/kube-bench:v0.7.3
    container_name: kube-bench
    profiles: ["tools", "kubernetes"]
    volumes:
      - ./kubeconfigs:/root/.kube:ro
      - ./reports/kube-bench:/reports
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: --config-dir /opt/kube-bench/cfg --outputfile /reports/kube-bench-report.json --json
    networks:
      - security-net
    restart: unless-stopped

  kubescape:
    image: quay.io/armosec/kubescape:latest
    container_name: kubescape
    profiles: ["tools", "kubernetes"]
    volumes:
      - ./kubeconfigs:/root/.kube:ro
      - ./reports/kubescape:/reports
    command: |
      scan
      --format json
      --output /reports/kubescape-results.json
      --submit=false
      --verbose
    networks:
      - security-net
    restart: unless-stopped

  kube-hunter:
    image: aquasec/kube-hunter:0.6.8
    container_name: kube-hunter
    profiles: ["tools", "kubernetes"]
    volumes:
      - ./kubeconfigs:/root/.kube:ro
      - ./reports/kube-hunter:/reports
    command: --report json --log /reports/kube-hunter.json
    networks:
      - security-net
    restart: unless-stopped

  trivy:
    image: aquasec/trivy:0.50.4
    container_name: trivy
    profiles: ["tools", "container"]
    volumes:
      - ./reports/trivy:/reports
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - trivy-cache:/root/.cache
    environment:
      - TRIVY_CACHE_DIR=/root/.cache
    command: --cache-dir /root/.cache
    networks:
      - security-net
    restart: unless-stopped

  grype:
    image: anchore/grype:v0.77.4
    container_name: grype
    profiles: ["tools", "container"]
    volumes:
      - ./reports/grype:/reports
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - grype-cache:/root/.cache
    environment:
      - GRYPE_DB_CACHE_DIR=/root/.cache
    networks:
      - security-net
    restart: unless-stopped

  popeye:
    image: derailed/popeye:v0.21.3
    container_name: popeye
    profiles: ["tools", "kubernetes"]
    volumes:
      - ./kubeconfigs:/root/.kube:ro
      - ./reports/popeye:/reports
    command: --output json --save --output-file /reports/popeye-report.json
    networks:
      - security-net
    restart: unless-stopped

  kube-linter:
    image: stackrox/kube-linter:v0.6.8
    container_name: kube-linter
    profiles: ["tools", "kubernetes", "iac"]
    volumes:
      - ./kubeconfigs:/root/.kube:ro
      - ./reports/kube-linter:/reports
      - ./iac-code:/manifests:ro
    command: lint /manifests --format json --output /reports/kube-linter-results.json
    networks:
      - security-net
    restart: unless-stopped

  polaris:
    image: quay.io/fairwinds/polaris:9.0.1
    container_name: polaris
    profiles: ["tools", "kubernetes", "iac"]
    volumes:
      - ./kubeconfigs:/root/.kube:ro
      - ./reports/polaris:/reports
      - ./iac-code:/manifests:ro
    command: audit --audit-path /manifests --format json --output-file /reports/polaris-results.json
    networks:
      - security-net
    restart: unless-stopped

  falco:
    image: falcosecurity/falco-no-driver:0.37.1
    container_name: falco
    profiles: ["tools", "kubernetes"]
    privileged: true
    volumes:
      - /var/run/docker.sock:/host/var/run/docker.sock:ro
      - ./config/falco:/etc/falco:ro
      - ./logs/falco:/var/log/falco
    environment:
      - HOST_ROOT=/host
    command: -o json_output=true -o json_output_file=/var/log/falco/events.json
    networks:
      - security-net
    restart: unless-stopped

  # ============================================================================
  # Infrastructure-as-Code Security
  # ============================================================================

  checkov:
    image: bridgecrew/checkov:3.2.74
    container_name: checkov
    profiles: ["tools", "iac"]
    volumes:
      - ./iac-code:/code:ro
      - ./reports/checkov:/reports
    command: |
      -d /code
      --output json
      --output-file-path /reports
      --framework terraform cloudformation kubernetes helm arm
      --quiet
    networks:
      - security-net
    restart: unless-stopped

  terrascan:
    image: tenable/terrascan:latest
    container_name: terrascan
    profiles: ["tools", "iac"]
    volumes:
      - ./iac-code:/iac:ro
      - ./reports/terrascan:/reports
    command: |
      scan
      -d /iac
      -o json
      -f /reports/terrascan-results.json
    networks:
      - security-net
    restart: unless-stopped

  tfsec:
    image: aquasec/tfsec:v1.28.6
    container_name: tfsec
    profiles: ["tools", "iac"]
    volumes:
      - ./iac-code:/src:ro
      - ./reports/tfsec:/reports
    command: |
      /src
      --format json
      --out /reports/tfsec-results.json
      --soft-fail
    networks:
      - security-net
    restart: unless-stopped

  # ============================================================================
  # Asset Mapping & Visualization
  # ============================================================================

  cartography:
    image: ghcr.io/lyft/cartography:0.94.0
    container_name: cartography
    profiles: ["tools", "aws"]
    depends_on:
      - neo4j
    volumes:
      - ./credentials/aws:/root/.aws:ro
      - ./credentials/gcp:/root/.config/gcp:ro
      - ./logs:/logs
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-cloudsecurity}
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
      - GOOGLE_APPLICATION_CREDENTIALS=/root/.config/gcp/credentials.json
    command: --neo4j-uri bolt://neo4j:7687 --neo4j-user neo4j --neo4j-password ${NEO4J_PASSWORD:-cloudsecurity}
    networks:
      - security-net
    restart: unless-stopped

  neo4j:
    image: neo4j:5.18.1-community
    container_name: neo4j
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-cloudsecurity}
      - NEO4J_dbms_memory_heap_max__size=4G
      - NEO4J_dbms_memory_pagecache_size=2G
    ports:
      - "${NEO4J_HTTP_PORT:-7474}:7474"
      - "${NEO4J_BOLT_PORT:-7687}:7687"
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-plugins:/plugins
    networks:
      - security-net
    healthcheck:
      test: ["CMD", "neo4j", "status"]
      interval: 30s
      timeout: 10s
      retries: 5
    # Security hardening disabled for Docker Desktop compatibility
    # security_opt:
    #   - no-new-privileges:true
    # cap_drop:
    #   - ALL
    # cap_add:
    #   - CHOWN
    #   - SETGID
    #   - SETUID
    restart: unless-stopped

  # ============================================================================
  # Storage & Database
  # ============================================================================

  postgresql:
    image: postgres:15.6-alpine
    container_name: postgresql
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-security_audits}
      - POSTGRES_USER=${POSTGRES_USER:-auditor}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro
      - ./logs/postgresql:/var/log/postgresql
    networks:
      - security-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-auditor}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Security hardening
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_READ_SEARCH
      - FOWNER
    restart: unless-stopped

  # ============================================================================
  # Web Interface & Reports
  # ============================================================================

  nginx:
    build: ./frontend
    image: nubicustos-frontend:local
    container_name: nginx
    ports:
      - "${NGINX_PORT:-8080}:80"
    volumes:
      - ./reports:/reports:ro
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./logs/nginx:/var/log/nginx
    networks:
      - security-net
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1/"]
      interval: 30s
      timeout: 10s
      retries: 3
    # Security hardening
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - NET_BIND_SERVICE
    read_only: true
    tmpfs:
      - /var/cache/nginx:mode=1777,size=64m
      - /run:mode=1777,size=16m
    restart: unless-stopped

  # ============================================================================
  # REST API
  # ============================================================================

  api:
    build: ./api
    container_name: security-api
    ports:
      - "${API_PORT:-8000}:8000"
    environment:
      - DB_HOST=postgresql
      - DB_PORT=5432
      - DB_NAME=${POSTGRES_DB:-security_audits}
      - DB_USER=${POSTGRES_USER:-auditor}
      - DB_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-cloudsecurity}
      - API_KEY=${API_KEY:-}
      - API_CORS_ORIGINS=${API_CORS_ORIGINS:-http://localhost:8080,http://localhost:3000}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_FORMAT=${LOG_FORMAT:-json}
      - SHUTDOWN_TIMEOUT=${SHUTDOWN_TIMEOUT:-30}
      - HOST_REPORTS_PATH=${HOST_REPORTS_PATH:-${PWD}/reports}
      - HOST_PROJECT_PATH=${HOST_PROJECT_PATH:-${PWD}}
    volumes:
      - ./reports:/reports:rw
      - ./scripts:/app/scripts:ro
      - ./report-processor:/app/report-processor:ro
      - ./credentials/aws:/app/credentials/aws:rw
      - ./credentials/azure:/app/credentials/azure:rw
      - /var/run/docker.sock:/var/run/docker.sock:ro
      # Tool build contexts for on-demand image building
      - ./tools:/app/tools:ro
      - ./docker:/app/docker:ro
      - ./cloudmapper:/app/cloudmapper:ro
      # IaC file staging for upload-based scanning
      - ./iac-staging:/app/iac-staging:rw
    depends_on:
      postgresql:
        condition: service_healthy
    networks:
      - security-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    # Security hardening
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    read_only: true
    tmpfs:
      - /tmp:mode=1777,size=64m
      - /processed:mode=1777,size=128m
    # Docker socket access for tool execution (required for CloudFox, Pacu, etc.)
    group_add:
      - "0"  # Docker socket group on Windows/Mac
    restart: unless-stopped

  # ============================================================================
  # Report Processor
  # ============================================================================

  report-processor:
    build: ./report-processor
    container_name: report-processor
    working_dir: /app
    environment:
      - DB_HOST=postgresql
      - DB_PORT=5432
      - DB_NAME=${POSTGRES_DB:-security_audits}
      - DB_USER=${POSTGRES_USER:-auditor}
      - DB_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - AWS_SHARED_CREDENTIALS_FILE=/root/.aws/credentials
      - AWS_CONFIG_FILE=/root/.aws/config
    volumes:
      - ./reports:/reports:rw
      - ./credentials/aws:/root/.aws:ro
    depends_on:
      postgresql:
        condition: service_healthy
    networks:
      - security-net
    restart: unless-stopped

# ============================================================================
# Networks
# ============================================================================

networks:
  security-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

# ============================================================================
# Volumes
# ============================================================================

volumes:
  postgres-data:
    driver: local
  neo4j-data:
    driver: local
  neo4j-logs:
    driver: local
  neo4j-plugins:
    driver: local
  pacu-data:
    driver: local
  trivy-cache:
    driver: local
  grype-cache:
    driver: local
  cloudfox-data:
    driver: local
